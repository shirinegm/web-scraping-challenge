{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pymongo\n",
    "import time\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95658cf",
   "metadata": {},
   "source": [
    "# Scape Source 1 - NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Chrome Driver because the news articles here are generated dynamically\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a04d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the url for NASA Mars News and use the headless browser to visit it\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "# Get the html object\n",
    "html = browser.html\n",
    "\n",
    "# Parse the html object\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Get all the relevant elements for news\n",
    "results = soup.find_all('div', class_='list_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243cca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results are valid\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9283d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through results and pull title and paragraph\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return title of news post\n",
    "        title = result.find('div', class_='content_title').text\n",
    "        # Identify and return paragraph of news post\n",
    "        paragraph = result.find('div', class_='article_teaser_body').text\n",
    "\n",
    "        # Run only if title and paragraph are available\n",
    "        if (title and paragraph):\n",
    "            # Print results\n",
    "            print('-------------')\n",
    "            print(title)\n",
    "            print(paragraph)\n",
    "\n",
    "            # Dictionary to be inserted as a MongoDB document\n",
    "            post = {\n",
    "                'title': title,\n",
    "                'paragraph': paragraph,\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a33b89",
   "metadata": {},
   "source": [
    "# Scape Source 2 - JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52a46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb160f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "# Get the html object\n",
    "html = browser.html\n",
    "\n",
    "# Parse the html object\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Find a tag where class is brand_title\n",
    "results = soup.find('div', class_='floating_text_area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4da270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the url from the href attribute\n",
    "relimageurl = results.find('a', href=True)\n",
    "relimageurl['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign it to a variable and concatenate it with the main url of the site\n",
    "featured_image_url = url +relimageurl['href']\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fa14b",
   "metadata": {},
   "source": [
    "# Scrape Source 3 - Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the source to scrap\n",
    "url = 'https://galaxyfacts-mars.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to get the table from the url. It is returned as a list so get the first instance to get the dataframe\n",
    "facts_list = pd.read_html(url)\n",
    "facts_df = facts_list[0]\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the first row as column headers\n",
    "facts_df.columns = facts_df.iloc[0]\n",
    "facts_df = facts_df[1:]\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the right column as index\n",
    "facts_df = facts_df.set_index('Mars - Earth Comparison')\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it to a html string\n",
    "facts_html = facts_df.to_html()\n",
    "facts_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745923e",
   "metadata": {},
   "source": [
    "# Scrape Source 4 - Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56359263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the list of urls to go after\n",
    "urllist = ['https://marshemispheres.com/cerberus.html',\n",
    "            'https://marshemispheres.com/schiaparelli.html',\n",
    "            'https://marshemispheres.com/syrtis.html',\n",
    "            'https://marshemispheres.com/valles.html']\n",
    "\n",
    "# Declare an empty list to hold the final scrap\n",
    "image_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d5fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageInfo(url):\n",
    "    # Declare an empty dict to be populated and returned\n",
    "    dict = {}\n",
    "    # Retrieve page with the requests module\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Create bs object; parse with 'html.parser'\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    \n",
    "    # Find the title and relative url of the image\n",
    "    imageinfo = soup.find('div', class_='cover')\n",
    "    title = imageinfo.find('h2', class_='title').text\n",
    "    relimageurl = imageinfo.find('a', href=True)\n",
    "    imageurl = url + relimageurl['href']\n",
    "    \n",
    "    # Populate the dictionary with the retrieved info\n",
    "    dict = {\"title\": title, \"img_url\": imageurl}\n",
    "    return dict\n",
    "\n",
    "# Test out our new method\n",
    "getImageInfo('https://marshemispheres.com/cerberus.html')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urllist:\n",
    "    image_list.append(getImageInfo(url))\n",
    "image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be polite and close the browser\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
